# 特点
1. 包含一个线程队列和任务队列，任务队列用于存储待执行的任务
2. 线程池在启动时会创建一定数量的线程，并把它们放入线程队列中
3. 当有任务需要执行时，线程池从任务队列中获取任务，并且将其分配给空闲的线程执行
4. 执行完任务的线程会继续等待下一个任务的到来，而不是被销毁
5. 如果任务队列为空，线程池中的线程可以进入睡眠状态，减少资源占用
6. 线程池可以限制同时执行的线程数量，避免过多的并发线程导致的系统负载过高

# 实现
首先线程池应该是不应该被拷贝的，所以我们的线程池应该是以单例的模式存在

单例模式就是要删除拷贝构造和拷贝复制，我们需要设计一个基类

```C++
#ifndef NOCOPY_H
#define NOCOPY_H

// 禁止子类复制
class NoCopy{
public:
    ~NoCopy(){};
protected:
    NoCopy(){};
private:
    NoCopy(const NoCopy&) = delete;
    NoCopy& operator=(const NoCopy&) = delete;
};

#endif
```

```C++
#ifndef THREADPOOL_H
#define THREADPOOL_H
#include "nocopy.h"
#include <condition_variable>
#include <future>
#include <memory>
#include <mutex>
#include <queue>
#include <thread>
#include <utility>
#include <vector>
#include <functional>

class ThreadPool : public NoCopy{
public:
    using Task = std::packaged_task<void()>;
    ~ThreadPool(){
        stop();
    }

    static ThreadPool& Instance(){
        static ThreadPool ins;
        return ins;
    }

    int IdelThreadNum(){
        return thread_num_;
    }

    template<class F, class ...Args>
    auto commit(F&& f, Args&& ...args) -> std::future<decltype(f(args...))> {
        using RetType = decltype(f(args...));
        if(stop_.load())
            return std::future<RetType>{};
        
        auto task = std::make_shared<std::packaged_task<RetType()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));

        std::future<RetType> ret = task->get_future();
        {
            std::lock_guard<std::mutex> lck(mtx_);
            tasks_.emplace([task]{(*task)();});
        }
    
        cv_lock_.notify_one();
        return ret;
    }

private:
    ThreadPool(unsigned int num = std::thread::hardware_concurrency()){
        if(num == 1)
            thread_num_ = 2;
        else 
            thread_num_ = num;

        start();
    }
    
    void stop(){
        stop_.store(true);
        cv_lock_.notify_all();
        for(auto& td : pool_){
            if(td.joinable()){
                td.join();
            }
        }
    }

    void start(){
        for(int i = 0; i < thread_num_; ++i){
            pool_.emplace_back([this](){
                while(!this->stop_.load()){
                    Task task;
                    {
                        std::unique_lock<std::mutex> lck(mtx_);
                        this->cv_lock_.wait(lck, [this](){
                            return this->stop_.load() || !this->tasks_.empty();
                        });

                        if(this->tasks_.empty())
                            return;

                        task = std::move(this->tasks_.front());
                        this->tasks_.pop();
                    }
                    thread_num_--;
                    task();
                    thread_num_++;
                }
            });
        }
    }

private:
    std::mutex mtx_;
    std::atomic_int thread_num_;
    std::atomic_bool stop_;
    std::condition_variable cv_lock_;
    std::queue<Task> tasks_;
    std::vector<std::thread> pool_;
};

#endif
```