# 图像增广
## 随机裁剪
由于图像不全是完全符合我们模型的输入要求的，我们可以采取随机裁剪的方式来裁剪图片的子模块来使得图像符合要求

**通过这种方式，我们不仅可以得到符合我们模型输入要求的图像，还可以获得更丰富的输入数据，提高模型的泛化能力和鲁棒性**

参考代码：
```python
def rand_crop(feature, label, height, width):  
    """  
    为了使得图像符合模型的输入，我们对图像进行随机裁剪  
    :param feature: 要裁剪的原图像  
    :param label: 图像标注  
    :param height: 图像高  
    :param width: 图像宽  
    :return: 裁剪后的子图和子标注  
    """    # 生成一个在原图像上随机裁剪出一个子图像的位置参数； i、j：起始像素，h、w：在起始像素后多长距离  
    i, j, h, w = torchvision.transforms.RandomCrop.get_params(feature, output_size=(height, width))  
    # 生成子图  
    feature = torchvision.transforms.functional.crop(feature, i, j, h, w)  
    label = torchvision.transforms.functional.crop(label, i, j, h, w)  
    return feature, label
```

# 通道
更普遍的图片表达方式是RGB颜色模型，即红、绿、蓝三原色的色光以不同的比例相加，以产生多种多样的色光。RGB颜色模型中，单个矩阵就扩展成了有序排列的三个矩阵，也可以用三维张量去理解。

其中的每一个矩阵又叫这个图片的一个channel（通道），宽, 高, 深来描述。
![[Pasted image 20241124182423.png]]
所以可以理解这一步
```Python
self.rgb_mean = np.array([0.485, 0.456, 0.406])  
self.rgb_std = np.array([0.229, 0.224, 0.225])  
self.tsf = torchvision.transforms.Compose([  
    torchvision.transforms.ToTensor(),  
    torchvision.transforms.Normalize(mean=self.rgb_mean, std=self.rgb_std)])
```
实际也就是在**通道**层面对数据进行归一化

# 卷积神经网络
[【深度学习】一文搞懂卷积神经网络（CNN）的原理（超详细）_卷积神经网络原理-CSDN博客](https://blog.csdn.net/AI_dataloads/article/details/133250229)
[机器学习算法之——卷积神经网络(CNN)原理讲解 - 知乎](https://zhuanlan.zhihu.com/p/156926543)
