# 简介
哨兵巡查监控后台master主机是否故障，如果故障了根据<span style="color:rgb(255, 0, 0)">投票数</span>自动将某一个从库转换为新的主库，继续对外服务

哨兵的作用：
1. 监控redis的运行状态，包括slave和master
2. 当master挂了，自动将slave切换为master


功能：
1. 主从监控
2. 消息通知：哨兵可以将故障转移的结果发送给客户端
3. 故障转移：如果master故障，则会自动进行主从切换
4. 配置中心：客户端通过连接哨兵来获取当前redis服务的主节点地址

# 案例演示
## 架构说明
* 一主二从：用于数据读取和存放
* 三个哨兵：自动监控和维护集群，不存放数据
![[Pasted image 20240708152047.png]]

为什么要配三个哨兵：
* 一个挂了不影响
* 奇数好投票
* 哨兵也要配集群，保证高可用

## 操作
在用户定义的目录下创建`sentinel.conf`文件，<span style="color:rgb(255, 0, 0)">名字绝对不能出错</span> 

在redis的安装包里面也带了默认的`sentinel.conf`文件，可以先看看它是怎么写的

### 参数说明
redis自带的`sentinel.conf`文件中部分参数说明
* bind：服务监听地址，用于客户端连接，默认是本机地址
* daemonize：是否以守护进程的方式运行
* protected-mode：安全保护模式
* port：端口
* logfile：日志文件路径
* pidfile：pid文件路径
* dir：工作目录

#### 重要参数
```
sentinel monitor <master-name> <ip> <redis-port> <quorum>
```
设置要监控的master主机
quorum：表示最少几个哨兵认可客观下线，统一故障迁移的法定票数
![[Pasted image 20240708154013.png]]

因为网络是不可靠的，有时候sentinel会因为网络问题误以为一个master节点已经挂掉了。在sentinel集群中，需要多个sentinel互相沟通来确认这个master节点是不是真的挂了，quornum就是进行客观下线的参数。意思是至少有<span style="color:rgb(255, 0, 0)">quorum个sentinel认为这个master存在问题</span>，才会对这个master进行下线和故障转移。这样就<span style="color:rgb(255, 0, 0)">避免了单个sentinel因为网络问题而将正常master错误下线</span> 

```
sentinel auth-pass <master-name> <password>
```
![[Pasted image 20240708154410.png]]
master设置了密码，连接master服务的密码
![[Pasted image 20240708154543.png]]

改完之后大概内容就是这样：
![[Pasted image 20240708160451.png]]

### 启动哨兵
哨兵默认的端口和redis存储服务不同，默认为26379，<span style="color:rgb(255, 0, 0)">哨兵的端口也要不一样</span>
![[Pasted image 20240708160207.png]]
![[Pasted image 20240708160244.png]]

```shell
redis-sentinel /path/to/sentinel.conf
```
来启动集群
```
redis-server /path/to/sentinel.config --sentinel
```
也行

哨兵的设置不需要管slave的，master会告诉sentinel有关slave的信息。多个sentinel也是通过master了解其他sentinel的存在，并且将slave和其他sentinel的信息重新写入`sentinel.conf`



### 下线处理
当master下线后，sentinel将会进行投票将master客观下线，同时选举新的master

旧的master下线到新的master被投票选出需要一定的时间来切换，这时候原来的slave将会断开连接，也会报错`broken pipe`
![[Pasted image 20240708162253.png]]
这是因为旧的master下线

如果旧的master上线，也会被降级为slave，不会影响新的master

如果旧的maste<span style="color:rgb(255, 0, 0)">r没有在配置文件中写</span>`masterauth`，也就是密码，会报`auth`有关错误。<span style="color:rgb(255, 0, 0)">旧的master是不需要配置</span>`replicaof`，也就是master的有关信息的，`sentinel`会在配置文件中自动为我们加入

同时原来的slave的`replicaof`的信息也会被`sentinel`自动注释，也就是注释掉了主机的有关信息

也就是<span style="color:rgb(255, 0, 0)">配置文件</span>会在运行期间被`sentinel`<span style="color:rgb(255, 0, 0)">自动修改</span>，同时`sentinel`的<span style="color:rgb(255, 0, 0)">监控目标也会被自动切换</span> 

# 运行流程和选举原理
1. 正常运行，三个哨兵，一主二从
2. SDown(Subjectively Down)下线
单个sentinel自己主观上认为master出现了问题，无法响应。默认是30s，30s内还没有回复，单个sentinel主观上认为master下线了
3. ODown(Object Down)客观下线
多个哨兵达成意见，也就是多个哨兵都认为这个master下线了，quorum个哨兵认为master下限了，就对master进行客观下线
4. 选出slave中的最好的一个，作为master。这个操作将<span style="color:rgb(255, 0, 0)">从三个sentinel中选出一个被赋予leader权限</span> (<span style="color:rgb(112, 48, 160)">使用Raft算法选出的</span>)，由这个sentinel在slave中选出一个升格为master(上面这一系列操作都可以在sentinel.conf中看出来)，

## Raft算法
基本原理就是先到先得，如果哨兵A向哨兵B发送请求，请求B支持A成为leader，如果B还没有收到别人的请求，则B支持A，这样。这样，再经过票数统计，最后谁收到的支持多，谁就成为Leader。

总的一句话就是谁发动自荐快，谁就成为leader。

有一定的道理的，最快发出自荐的理论上要么运行速度快，要么网络延迟低。所以Raft算法大概率能选出一个不错的leader

## Leader选取新master的过程
### 选出新的master
leader如何在几个slave中选择最新的master？
![[Pasted image 20240708201503.png]]

在slave节点健康的前提下，三个步骤：
1. 看权限，redis.conf中有一个`slave-priority`或者`replica-priority`属性，数字越小，优先级越高
2. 看复制偏移量，看谁的数据和原来的master最接近
3. 看RunID，谁RunID最小，就选择谁

由1到3，直到选出一个master

### 旧slave指向新的master
被选出的master会执行`slaveof no one`，成为master节点，并且通过`slaveof`命令让其他节点成为新master节点的slave

### 旧master成为新的master的slave
旧的master执行`slaveof`，成为新的master的slave

# 使用建议
1. 哨兵也要是多个，哨兵本身就应该是集群，来保证高可用
2. 哨兵节点的数量最好是奇数个，方便投票
3. 各个哨兵节点的配置应该一致，除了<span style="color:rgb(255, 0, 0)">端口</span> 
4. 如果哨兵配置在docker里面，要注意端口的正确映射
5. 哨兵集群+主从复制，也不能保证数据不丢失（因为数据量大了，master挂了，slave不一定完全复制了master）